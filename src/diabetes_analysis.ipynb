{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ad668618",
   "metadata": {},
   "source": [
    "# Diabetes Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aff60972",
   "metadata": {},
   "source": [
    "Data Reference: https://archive.ics.uci.edu/dataset/891/cdc+diabetes+health+indicators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "251f1162",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import altair as alt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c4f2084",
   "metadata": {},
   "source": [
    "## Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c917c06-cde5-4284-a333-aa22827f605b",
   "metadata": {},
   "source": [
    "This project attempts to predict diabetes status using the Logistic Regression and LinearSVC models, against a baseline DummyClassifier on an imbalanced dataset. All models achieved similar accuracy on the test set (approximately 0.86), which highlights a key issue: accuracy alone is not a reliable performance metric.\n",
    "\n",
    "These findings motivate deeper exploratory data analysis, evaluation with additional metrics (precision, recall, F1), and exploration of alternative models and threshold tuning to get a more robust assessment of the model's predictability. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd00c4b7",
   "metadata": {},
   "source": [
    "## Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3adc423-a8c7-4fc4-b9c8-c051d0b3e3eb",
   "metadata": {},
   "source": [
    "Diabetes is a chronic disease that prevents the body from properly controlling blood sugar levels, which can lead to serious health problems including heart disease, vision loss, kidney disease, and limb amputation (Teboul, 2020). Given the severity of the disease, early detection can allow people to make lifestyle changes and receive treatment that can slow disease progression. We believe that machine learning models using survey data can offer a promising way to create accessible, cost-effective screening tools to identify high-risk individuals and support public health efforts.\n",
    "\n",
    "### Research Question\n",
    "Can we use health indicators and lifestyle factors from the CDC's Behavioral Risk Factor Surveillance System (BRFSS) survey to accurately predict whether an individual has diabetes?\n",
    "\n",
    "We are looking to :\n",
    "1. Build and evaluate classification models that predict diabetes status based on 21 health and lifestyle features\n",
    "2. Compare the performance and efficiency of logistic regression and support vector machine (SVM) classifiers\n",
    "3. Assess whether survey-based features can provide sufficiently accurate predictions for practical screening applications"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20c157e1",
   "metadata": {},
   "source": [
    "## Methods & Results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c22af915-da34-4fb2-912e-069963d57423",
   "metadata": {},
   "source": [
    "This analysis uses the diabetes_binary_health_indicators_BRFSS2015.csv dataset, a cleaned and preprocessed version of the CDC's 2015 Behavioral Risk Factor Surveillance System (BRFSS) survey data, made available by Alex Teboul on Kaggle (Teboul, 2020).\n",
    "\n",
    "For this analysis, we split the dataset into training (80%) and testing (20%) sets using a fixed random state (522) to ensure reproducibility. We implemented two classification algorithms:\n",
    "\n",
    "1. Logistic Regression: A linear model appropriate for binary classification that estimates the probability of diabetes based on a linear combination of features.\n",
    "2. Linear Support Vector Classifier (SVC): A classifier that finds an optimal hyperplane to separate diabetic from non-diabetic individuals.\n",
    "\n",
    "Both models were implemented using scikit-learn pipelines that include feature standardization (StandardScaler) to normalize the numeric features to comparable scales. Binary categorical features were already processed in the dataset and were set to pass through the column transformer. We evaluated model performance using cross-validation on the training set and final accuracy assessment on the held-out test set.\n",
    "\n",
    "Our results show that both models achieve approximately 86% accuracy, with logistic regression demonstrating slightly faster training time."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91e9a80c",
   "metadata": {},
   "source": [
    "## Discussion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23adf66a-8758-433d-b020-92d2b1d50c84",
   "metadata": {},
   "source": [
    "The baseline DummyClassifier achieves an accuracy score of about 0.86, derived from assigning the most frequent class (non-diabetic) to all patients. This highlights how approximatey 86% of the dataset is non-diabetic. Both Logistic Regression and LinearSVC achieve similar accuracy (approximately 0.86) with little to no improvement.\n",
    "\n",
    "The EDA showed that there is class imbalance (more non-diabetic than diabetic patients) and this may affect the models’ reliability. Therefore, more analysis is needed to explore additional models, check class balance with metrics such as precision and recall, examine confusion matrices, and test different data splits or tune hyperparameters to determine if performance is stable across scenarios before drawing strong conclusions.\n",
    "\n",
    "The similarity in test scores is an unexpected finding. With a clean dataset containing informative and diverse features, we would expect the classification models to perform at least better than the dummy classifier. Additionally, initial hyperparameter tuning for logistic regression did not affect accuracy (data not shown). This finding highlights the importance of understanding the data through EDA to interpret where accuracy scores come from.\n",
    "\n",
    "This suggests the next step for deeper EDA, including distributions, to see whether features overlap and whether the model can separate them effectively. Other future questions would be determining which features are most important for classifying an individual as diabetic or not, evaluating the probability estimates, and assessing whether all features are truly helpful for drawing conclusions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fc7f3a4",
   "metadata": {},
   "source": [
    "## Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c6d62ae",
   "metadata": {},
   "source": [
    "### Read in Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e7beeb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ucimlrepo import fetch_ucirepo \n",
    "   \n",
    "cdc_diabetes_health_indicators = fetch_ucirepo(id=891) \n",
    "  \n",
    "dat = cdc_diabetes_health_indicators.data.original"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d4240a4",
   "metadata": {},
   "source": [
    "### Train Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ad14f13",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import cross_val_score, cross_validate, train_test_split\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "train_df, test_df = train_test_split(dat, test_size=0.2, random_state=522)\n",
    "\n",
    "X_train, y_train = (\n",
    "    train_df.drop(columns=[\"Diabetes_binary\"]),\n",
    "    train_df[\"Diabetes_binary\"],\n",
    ")\n",
    "X_test, y_test = (\n",
    "    test_df.drop(columns=[\"Diabetes_binary\"]),\n",
    "    test_df[\"Diabetes_binary\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff504e0f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "202abe4a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "830cee0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "190a4e04",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f48b9659",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25dbb4fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31f4aecb",
   "metadata": {},
   "source": [
    "### Data Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "304df981-572e-4992-9880-797f98e4562d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pointblank as pb\n",
    "########################## Data Validation: Correct file format\n",
    "\n",
    "## Checks that the training data has exactly the same number of columns as the \n",
    "## DataFrame itself (validates the column count)\n",
    "validation_1_1 = (\n",
    "    pb.Validate(data=train_df)\n",
    "    .col_count_match(len(train_df.columns))\n",
    "    .interrogate()\n",
    ")\n",
    "\n",
    "## Checks that the training data has correct number of observations/rows\n",
    "## 80% split for training data from the total of original data instances.\n",
    "rows, cols = dat.shape\n",
    "train_target = int(rows * 0.8)\n",
    "\n",
    "validation_1_2 = (\n",
    "    pb.Validate(data=train_df)\n",
    "    .row_count_match(train_target)\n",
    "    .interrogate()\n",
    ")\n",
    "\n",
    "validation_1_1\n",
    "validation_1_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1156096-4ceb-4473-802d-befd54e27809",
   "metadata": {},
   "outputs": [],
   "source": [
    "########################## Data Validation: Correct column names\n",
    "### Check that data contains all required column names and matches the expected schema.\n",
    "expected_columns = ['ID', 'Diabetes_binary', 'HighBP', 'HighChol', 'CholCheck', 'BMI',\n",
    "                   'Smoker', 'Stroke', 'HeartDiseaseorAttack', 'PhysActivity', 'Fruits',\n",
    "                   'Veggies', 'HvyAlcoholConsump', 'AnyHealthcare', 'NoDocbcCost',\n",
    "                   'GenHlth', 'MentHlth', 'PhysHlth', 'DiffWalk', 'Sex', 'Age',\n",
    "                   'Education', 'Income']\n",
    "validation_2 = (\n",
    "    pb.Validate(data = train_df)\n",
    "    .col_exists(columns = expected_columns)\n",
    "    .interrogate()\n",
    ")\n",
    "validation_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1d862d0-a3e0-48ab-84af-2c8709e3df0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "########################## Data Validation: No empty observations\n",
    "## Checks that all rows are complete and contain no missing values.\n",
    "validation_3 = (\n",
    "    pb.Validate(data = train_df)\n",
    "    .rows_complete() \n",
    "    .interrogate()\n",
    ")\n",
    "validation_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e040161-ad50-4a7a-a9a6-dd5402dd1f79",
   "metadata": {},
   "outputs": [],
   "source": [
    "########################## Data Validation: No empty observations\n",
    "## Checks that each column has 100 % non-missing values. There are no missing values in dataset. \n",
    "threshold = 1  # There are no missing values.\n",
    "\n",
    "validator = pb.Validate(data=train_df)\n",
    "\n",
    "for col in train_df.columns:\n",
    "    validator = validator.col_vals_not_null(columns=str(col), thresholds=threshold)\n",
    "\n",
    "validation_4 = validator.interrogate()\n",
    "validation_4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "043e089c",
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_features = [\"BMI\"]\n",
    "binary_features = [\"HighBP\", \"HighChol\", \"CholCheck\", \"Smoker\", \"Stroke\", \n",
    "                   \"HeartDiseaseorAttack\", \"PhysActivity\", \"Fruits\", \"Veggies\", \"HvyAlcoholConsump\", \n",
    "                   \"AnyHealthcare\", \"NoDocbcCost\", \"DiffWalk\", \"Sex\"]\n",
    "ordinal_features = [\"GenHlth\", \"MentHlth\", \"PhysHlth\", \"Age\", \"Education\", \"Income\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6eb6cea8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pointblank as pb\n",
    "\n",
    "########################## Data Validation: Correct data types in each column\n",
    "################ If fails: Critical checks (schema) -> Let it fail naturally and stop the pipeline\n",
    "schema_columns = [(col, \"int64\") for col in train_df.columns]\n",
    "schema = pb.Schema(columns=schema_columns)\n",
    "(\n",
    "    pb.Validate(data=train_df)\n",
    "    .col_schema_match(schema=schema)\n",
    "    .interrogate()\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f1e9617",
   "metadata": {},
   "outputs": [],
   "source": [
    "########################## Data Validation: No duplicate observations\n",
    "################ If fails: Non-Critical -> raise warnings and continue\n",
    "unique_key_cols = [\"ID\"]  # use only the primary key column \"ID\" \n",
    "try: \n",
    "    (\n",
    "        pb.Validate(data=train_df)\n",
    "        .rows_distinct(columns_subset=unique_key_cols)\n",
    "        .interrogate()\n",
    "    )\n",
    "except: \n",
    "    print(\"Data Validation failed: Duplicate Observation detected\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f90464d",
   "metadata": {},
   "outputs": [],
   "source": [
    "########################## Data Validation: No outlier or anomalous values for NUMERIC Features\n",
    "###### Through define acceptable numeric ranges \n",
    "## (based on the data collection method and domain knowledge)\n",
    "################ If fails: Non-Critical -> raise warnings and continue \n",
    "try: \n",
    "    (\n",
    "        pb.Validate(data=train_df)\n",
    "        .col_vals_between(columns=\"BMI\", left=10, right=100) # BMI is unlikely to go under 10 or exceed 100\n",
    "        .interrogate()\n",
    "    )\n",
    "except: \n",
    "    print(\"Data Validation failed: Outlier or anomalous values detected\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d5a077f",
   "metadata": {},
   "outputs": [],
   "source": [
    "################################## checking the value ranges for ordinal features\n",
    "for f in ordinal_features: \n",
    "    temp_col = train_df[f]\n",
    "    print(f\"========================================== {f}\")\n",
    "    print(f\"datatype: {temp_col.dtype}\")\n",
    "    print(temp_col.sort_values().value_counts().index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bad86b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "########################## Data Validation: Correct category levels for Category/Ordinal Features\n",
    "###### Through define acceptable value set or range\n",
    "## (based on the data collection method and domain knowledge)\n",
    "################ If fails: Non-Critical -> raise warnings and continue \n",
    "try: \n",
    "    (\n",
    "        pb.Validate(data=train_df)\n",
    "        .col_vals_in_set(columns=binary_features, set=[0,1]) # binary features: 0/1\n",
    "        .col_vals_in_set(columns=\"GenHlth\", set=list(range(1,6))) # scale of 1-5\n",
    "        .col_vals_between(columns=[\"MentHlth\", \"PhysHlth\"], left=0, right=30) # number of days out of 30 days\n",
    "        .col_vals_in_set(columns=\"Age\", set=list(range(1,14))) # scale of 1-13\n",
    "        .col_vals_in_set(columns=\"Education\", set=list(range(1,7))) # scale of 1-6\n",
    "        .col_vals_in_set(columns=\"Income\", set=list(range(1,9))) # scale of 1-8\n",
    "        .interrogate()\n",
    "    )\n",
    "except: \n",
    "    print(\"Data Validation failed: Incorrect category levels detected\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b116ef1",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2661a07f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from deepchecks.tabular import Dataset, Suite\n",
    "\n",
    "deep_train = Dataset(train_df.drop(columns=['ID']),\n",
    "                     label=\"Diabetes_binary\",\n",
    "                     cat_features=binary_features)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "363fc85d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from deepchecks.tabular.checks import ClassImbalance, FeatureLabelCorrelation, FeatureFeatureCorrelation\n",
    "import anywidget, ipywidgets\n",
    "\n",
    "########################## Data Validation: Check for class imbalance, anomalous results between feature-feature or feature-label\n",
    "### Having class imbalance for diabetes prediction is expected, isn't a warning about the dataset\n",
    "### Feature-label: Chose 0.5 as a threshold, given that it is variable health and lifestyle data and that it would be unexpected to find high coorelations for any one feature\n",
    "### Feature-Feature: watches for multicolinearity, set threhold higher because it's reasonable for some features to potentially be more coorelated here\n",
    "\n",
    "### Ian Gault: I looked up example on ChatGPT5 on how to use deepchecks for class imbalance and coorelations and what modules they would be in. I found the synthax with Suite and implemented that style here.  I was also running into errors packages being synced or needed for deepchecks, so found out more information about these errors too for debugging purposes.\n",
    "\n",
    "suite = Suite(\n",
    "    \"Validation\",\n",
    "    ClassImbalance(),\n",
    "    FeatureLabelCorrelation(correlation_threshold=0.5),\n",
    "    FeatureFeatureCorrelation(correlation_threshold=0.7),\n",
    ")\n",
    "\n",
    "suite_result = suite.run(deep_train)\n",
    "\n",
    "suite_result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12c93669",
   "metadata": {},
   "source": [
    "### Data Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8da9eec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the inbalance sample size of the two classes\n",
    "alt.data_transformers.enable('vegafusion')\n",
    "\n",
    "alt.Chart(train_df, title = \"Number of Records of Two Classes\").mark_bar().encode(\n",
    "    x = \"Diabetes_binary:N\", \n",
    "    y = \"count()\"\n",
    ").properties(\n",
    "    width=150,\n",
    "    height=250)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51630224",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Boxplot for Numeric Features\n",
    "alt.Chart(train_df).mark_boxplot().encode(\n",
    "    x=alt.X('Diabetes_binary:N', title='Diabetes (0/1)'),\n",
    "    y=alt.Y(alt.repeat('row'), type='quantitative')\n",
    ").properties(\n",
    "    width=200,\n",
    "    height=150\n",
    ").repeat(\n",
    "    row=numeric_features, \n",
    ")\n",
    "\n",
    "# Those having diabetes (diabetes_binary = 1) have a higher BMI on average"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e141ba2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bar Chart of Proportion with Diabetes for Binary Features\n",
    "alt.Chart(train_df).mark_bar().transform_fold(\n",
    "    binary_features,\n",
    "    as_=['feature', 'value']\n",
    ").encode(\n",
    "    x=alt.X('value:N', title='0 or 1'),\n",
    "    y=alt.Y('mean(Diabetes_binary):Q', title='Proportion with Diabetes'),\n",
    ").properties(\n",
    "    width=150, \n",
    "    height=150\n",
    ").facet(\n",
    "    facet='feature:N', \n",
    "    columns=5\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbf8dd4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bar Chart for Ordinal Features\n",
    "alt.Chart(train_df).mark_bar(size=20).encode(\n",
    "    x=alt.X(alt.repeat(\"row\"),type=\"quantitative\", sort=\"ascending\"), \n",
    "    y=\"count()\",\n",
    "    color=\"Diabetes_binary:N\",\n",
    "    column=alt.Column(\"Diabetes_binary:N\")\n",
    ").properties(\n",
    "    width=200, \n",
    "    height=150\n",
    ").repeat(\n",
    "    row=ordinal_features\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "751737c1",
   "metadata": {},
   "source": [
    "### Model Training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "656e4b02",
   "metadata": {},
   "source": [
    "#### Feature Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a44d460",
   "metadata": {},
   "outputs": [],
   "source": [
    "dat.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa5fedd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# features\n",
    "numeric_feats = [\"GenHlth\", \"Education\", \"Income\", \"Age\", \"MentHlth\", \"PhysHlth\", \"BMI\"]\n",
    "\n",
    "\n",
    "passthrough_feats = [\n",
    "    \"HighBP\",\n",
    "    \"HighChol\",\n",
    "    \"CholCheck\",\n",
    "    \"Smoker\",\n",
    "    \"Stroke\",\n",
    "    \"HeartDiseaseorAttack\",\n",
    "    \"PhysActivity\",\n",
    "    \"Fruits\",\n",
    "    \"Veggies\",\n",
    "    \"HvyAlcoholConsump\",\n",
    "    \"AnyHealthcare\",\n",
    "    \"NoDocbcCost\",\n",
    "    \"DiffWalk\",\n",
    "    \"Sex\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f2a9897",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.compose import make_column_transformer\n",
    "\n",
    "preprocessor = make_column_transformer(\n",
    "    (StandardScaler(), numeric_feats),\n",
    "    (\"passthrough\", passthrough_feats)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de0d7a65",
   "metadata": {},
   "source": [
    "#### Dummy Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ccdf358",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.dummy import DummyClassifier\n",
    "\n",
    "dummy_df = DummyClassifier(strategy=\"most_frequent\", random_state=552)\n",
    "\n",
    "scores_dummy = pd.DataFrame(cross_validate(dummy_df, X_train, y_train, return_train_score=True)).mean()\n",
    "scores_dummy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5a413d9",
   "metadata": {},
   "source": [
    "#### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "896f2f8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_pipe = make_pipeline(preprocessor, LogisticRegression(max_iter=1000))\n",
    "\n",
    "scores_logistic = cross_validate(lr_pipe, X_train, y_train, return_train_score=True)\n",
    "results = pd.DataFrame(scores_logistic)\n",
    "results.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8200c910",
   "metadata": {},
   "source": [
    "#### Linear SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e8d4aeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "linear_svc_pipe = make_pipeline(preprocessor, LinearSVC(max_iter=5000))\n",
    "\n",
    "scores = cross_validate(linear_svc_pipe, X_train, y_train, return_train_score=True)\n",
    "results = pd.DataFrame(scores)\n",
    "results.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2959a9d4",
   "metadata": {},
   "source": [
    "#### Final Test (predict on the testset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a558634",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "lr_pipe.fit(X_train, y_train)\n",
    "prediction_lr = lr_pipe.predict(X_test)\n",
    "accuracy_lr = accuracy_score(y_test, prediction_lr)\n",
    "\n",
    "linear_svc_pipe.fit(X_train, y_train)\n",
    "prediction_svc = linear_svc_pipe.predict(X_test)\n",
    "accuracy_svc = accuracy_score(y_test, prediction_svc)\n",
    "print(f\"The accuracy of the Logistic Regression model is {accuracy_lr}\")\n",
    "print(f\"The accuracy of Linear SVC model is {accuracy_svc}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d31456d",
   "metadata": {},
   "source": [
    "## Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3ed96c5",
   "metadata": {},
   "source": [
    "After training, Logistic Regression and Linear SVC produced similar accuracy on X_test (about 86%), with Logistic Regression training faster. Given the small difference, either model could be chosen for further evaluation; if speed and interpretability/probability estimates are important, it would make sense to go with Logistic Regression.\n",
    "\n",
    "A higher-priority next step is addressing class imbalance and re-evaluating both models to see if they outperform the dummy classifier. This motivates deeper EDA, examining feature distributions and predictions, reviewing confusion matrices, and conducting hyperparameter tuning to test for potential improvements. At this point, we cannot draw firm conclusions about the models’ predictive ability based on the current dataset and features."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
